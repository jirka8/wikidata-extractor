#!/usr/bin/env python3
"""
WikiData SPARQL Extraktor - HlavnÃ­ skript

Extrakce dat o mÄ›stech, obcÃ­ch a vesnicÃ­ch z WikiData pomocÃ­ SPARQL dotazÅ¯.
"""

import sys
import argparse
import logging
from pathlib import Path
from typing import Optional, List
import time
from tqdm import tqdm

# Import modulÅ¯
from src.config_manager import Config, ConfigValidator
from src.query_builder import SPARQLQueryBuilder
from src.wikidata_client import WikiDataClient
from src.data_processor import DataProcessor
from src.csv_exporter import CSVExporter


# Verze
__version__ = "1.0.0"


def setup_logging(verbose: bool = False, quiet: bool = False, log_file: Optional[str] = None) -> None:
    """
    NastavenÃ­ logovÃ¡nÃ­.

    Args:
        verbose: DetailnÃ­ vÃ½pis
        quiet: MinimÃ¡lnÃ­ vÃ½pis
        log_file: Cesta k log souboru
    """
    # ÃšroveÅˆ logovÃ¡nÃ­
    if quiet:
        level = logging.WARNING
    elif verbose:
        level = logging.DEBUG
    else:
        level = logging.INFO

    # FormÃ¡t zprÃ¡v
    log_format = '%(asctime)s [%(levelname)s] %(message)s'
    date_format = '%Y-%m-%d %H:%M:%S'

    # Handlers
    handlers = []

    # Console handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    console_handler.setFormatter(logging.Formatter(log_format, date_format))
    handlers.append(console_handler)

    # File handler
    if log_file:
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.DEBUG)  # VÅ¾dy DEBUG do souboru
        file_handler.setFormatter(logging.Formatter(log_format, date_format))
        handlers.append(file_handler)

    # Konfigurace root loggeru
    logging.basicConfig(
        level=level,
        format=log_format,
        datefmt=date_format,
        handlers=handlers
    )


def parse_arguments() -> argparse.Namespace:
    """
    ParsovÃ¡nÃ­ argumentÅ¯ pÅ™Ã­kazovÃ© Å™Ã¡dky.

    Returns:
        Namespace s argumenty
    """
    parser = argparse.ArgumentParser(
        description='WikiData SPARQL Extraktor - Extrakce dat o mÄ›stech a obcÃ­ch',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
PÅ™Ã­klady pouÅ¾itÃ­:
  %(prog)s --config configs/czech_republic.yaml
  %(prog)s --country CZ --output czechia.csv
  %(prog)s --config configs/slovakia.yaml --dry-run
  %(prog)s --config config.yaml --verbose --log-file extractor.log
        """
    )

    # Verze
    parser.add_argument(
        '--version',
        action='version',
        version=f'%(prog)s {__version__}'
    )

    # Konfigurace
    config_group = parser.add_mutually_exclusive_group(required=True)
    config_group.add_argument(
        '--config',
        type=str,
        help='Cesta ke konfiguraÄnÃ­mu souboru'
    )
    config_group.add_argument(
        '--country',
        type=str,
        help='NÃ¡zev konfiguraÄnÃ­ho souboru (bez .yaml) z adresÃ¡Å™e configs/'
    )

    # VÃ½stup
    parser.add_argument(
        '--output',
        type=str,
        help='Cesta k vÃ½stupnÃ­mu CSV (pÅ™epÃ­Å¡e config)'
    )

    # Pole
    parser.add_argument(
        '--fields',
        type=str,
        help='Seznam polÃ­ oddÄ›lenÃ½ ÄÃ¡rkami (pÅ™epÃ­Å¡e config)'
    )

    # Limit vÃ½sledkÅ¯
    parser.add_argument(
        '--limit',
        type=int,
        help='MaximÃ¡lnÃ­ poÄet vÃ½sledkÅ¯ (pro testovÃ¡nÃ­, napÅ™. --limit 100)'
    )

    # LogovÃ¡nÃ­
    log_group = parser.add_mutually_exclusive_group()
    log_group.add_argument(
        '-v', '--verbose',
        action='store_true',
        help='DetailnÃ­ vÃ½pis'
    )
    log_group.add_argument(
        '-q', '--quiet',
        action='store_true',
        help='MinimÃ¡lnÃ­ vÃ½pis'
    )

    parser.add_argument(
        '--log-file',
        type=str,
        help='Cesta k log souboru'
    )

    # SpeciÃ¡lnÃ­ reÅ¾imy
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Pouze zobrazÃ­ SPARQL dotaz bez spuÅ¡tÄ›nÃ­'
    )

    parser.add_argument(
        '--validate-config',
        action='store_true',
        help='Pouze validuje konfiguraÄnÃ­ soubor'
    )

    parser.add_argument(
        '--test-connection',
        action='store_true',
        help='Testuje spojenÃ­ s WikiData'
    )

    parser.add_argument(
        '--create-report',
        action='store_true',
        help='VytvoÅ™Ã­ sumarizaÄnÃ­ report'
    )

    parser.add_argument(
        '--list-configs',
        action='store_true',
        help='ZobrazÃ­ seznam dostupnÃ½ch konfiguraÄnÃ­ch souborÅ¯'
    )

    return parser.parse_args()


def list_available_configs() -> List[str]:
    """
    ZÃ­skÃ¡ seznam dostupnÃ½ch konfiguraÄnÃ­ch souborÅ¯.

    Returns:
        Seznam nÃ¡zvÅ¯ konfiguraÄnÃ­ch souborÅ¯ (bez .yaml)
    """
    configs_dir = Path('configs')
    if not configs_dir.exists():
        return []

    config_files = sorted(configs_dir.glob('*.yaml'))
    return [f.stem for f in config_files]


def get_config_path(country_code: str) -> Path:
    """
    ZÃ­skÃ¡ cestu ke konfiguraÄnÃ­mu souboru.

    Podporuje:
    - PÅ™Ã­mÃ© nÃ¡zvy souborÅ¯ (napÅ™. 'czech_republic' â†’ configs/czech_republic.yaml)
    - Zkratky (napÅ™. 'CZ' â†’ configs/czech_republic.yaml)
    - Case-insensitive matching

    Args:
        country_code: NÃ¡zev konfiguraÄnÃ­ho souboru nebo zkratka zemÄ›

    Returns:
        Cesta ke konfiguraÄnÃ­mu souboru

    Raises:
        FileNotFoundError: Pokud konfiguraÄnÃ­ soubor neexistuje
    """
    # MapovÃ¡nÃ­ bÄ›Å¾nÃ½ch zkratek na nÃ¡zvy souborÅ¯ (pro zpÄ›tnou kompatibilitu)
    shortcuts = {
        'CZ': 'czech_republic',
        'SK': 'slovakia',
        'PL': 'poland',
        'DE': 'germany',
        'UK': 'united_kingdom',
        'GB': 'united_kingdom',
        'ENG': 'england'
    }

    # Pokus o pouÅ¾itÃ­ zkratky
    config_name = shortcuts.get(country_code.upper(), country_code)

    # MoÅ¾nÃ© cesty
    possible_paths = [
        Path(f'configs/{config_name}.yaml'),
        Path(f'configs/{config_name.lower()}.yaml'),
        Path(f'configs/{country_code}.yaml'),
        Path(f'configs/{country_code.lower()}.yaml')
    ]

    # NajÃ­t prvnÃ­ existujÃ­cÃ­ soubor
    for path in possible_paths:
        if path.exists():
            return path

    # Pokud soubor neexistuje, zobrazit dostupnÃ© konfigurace
    available = list_available_configs()
    error_msg = f"KonfiguraÄnÃ­ soubor pro '{country_code}' nenalezen.\n"
    error_msg += f"DostupnÃ© konfigurace: {', '.join(available)}"
    raise FileNotFoundError(error_msg)


def main() -> int:
    """
    HlavnÃ­ funkce aplikace.

    Returns:
        Exit kÃ³d (0 = ÃºspÄ›ch, 1 = chyba)
    """
    # ParsovÃ¡nÃ­ argumentÅ¯
    args = parse_arguments()

    # Seznam dostupnÃ½ch konfiguracÃ­ (nevyÅ¾aduje logovÃ¡nÃ­)
    if args.list_configs:
        available_configs = list_available_configs()
        print("\n" + "=" * 70)
        print("DostupnÃ© konfigurace:")
        print("=" * 70)
        for config_name in available_configs:
            print(f"  â€¢ {config_name}")
            # UkÃ¡zat jak pouÅ¾Ã­t
            shortcuts_reverse = {
                'czech_republic': 'CZ',
                'slovakia': 'SK',
                'poland': 'PL',
                'germany': 'DE',
                'united_kingdom': 'UK nebo GB',
                'england': 'ENG'
            }
            shortcut = shortcuts_reverse.get(config_name)
            if shortcut:
                print(f"    PouÅ¾itÃ­: --country {shortcut} nebo --country {config_name}")
            else:
                print(f"    PouÅ¾itÃ­: --country {config_name}")
        print("=" * 70)
        print("\nPÅ™Ã­klady:")
        print("  python wikidata_extractor.py --country CZ")
        print("  python wikidata_extractor.py --country czech_republic")
        print("  python wikidata_extractor.py --config configs/custom_config.yaml")
        print()
        return 0

    # NastavenÃ­ logovÃ¡nÃ­
    setup_logging(args.verbose, args.quiet, args.log_file)

    logger = logging.getLogger('WikiDataExtractor')

    try:
        # Banner
        logger.info("=" * 70)
        logger.info("WikiData SPARQL Extraktor v{}".format(__version__))
        logger.info("=" * 70)

        # UrÄenÃ­ konfiguraÄnÃ­ho souboru
        if args.config:
            config_path = Path(args.config)
        else:
            config_path = get_config_path(args.country)

        logger.info(f"ğŸ“‚ KonfiguraÄnÃ­ soubor: {config_path}")

        # NaÄtenÃ­ konfigurace
        config = Config(config_path)

        # Validace konfigurace
        if args.validate_config:
            logger.info("âœ… Konfigurace je validnÃ­")
            return 0

        # VytvoÅ™enÃ­ komponent
        query_builder = SPARQLQueryBuilder(config)
        client = WikiDataClient(config)
        processor = DataProcessor(config)
        exporter = CSVExporter(config)

        # SestavenÃ­ SPARQL dotazu
        sparql_query = query_builder.build_query(limit=args.limit)

        # Informace o dotazu
        query_info = query_builder.get_query_info()
        logger.info(f"ğŸ¯ CÃ­l: {query_info['country']} ({query_info['country_qid']})")
        logger.info(f"ğŸ“Š DatovÃ¡ pole: {query_info['fields_count']} "
                   f"(povinnÃ½ch: {query_info['required_fields']}, "
                   f"volitelnÃ½ch: {query_info['optional_fields']})")

        # Dry run - zobrazenÃ­ dotazu
        if args.dry_run:
            logger.info("\n" + "=" * 70)
            logger.info("SPARQL Dotaz:")
            logger.info("=" * 70)
            print(sparql_query)
            logger.info("=" * 70)
            return 0

        # Test spojenÃ­
        if args.test_connection:
            success = client.test_connection()
            return 0 if success else 1

        # MÄ›Å™enÃ­ Äasu
        start_time = time.time()

        # StaÅ¾enÃ­ dat
        logger.info("ğŸš€ Zahajuji stahovÃ¡nÃ­ dat z WikiData...")
        
        strategy = config.get('query_settings', 'strategy', default='single_query')
        logger.info(f"ğŸ’¡ PouÅ¾itÃ¡ strategie: {strategy}")

        raw_results = []

        if strategy == 'by_admin_level':
            batch_level = config.get('query_settings', 'batch_by_admin_level')
            if not batch_level:
                raise ValueError("Pro strategii 'by_admin_level' je nutnÃ© nastavit 'batch_by_admin_level'")

            # FÃ¡ze 1: ZÃ­skÃ¡nÃ­ administrativnÃ­ch celkÅ¯
            logger.info(f"FÃ¡ze 1: ZÃ­skÃ¡vÃ¡m administrativnÃ­ celky ÃºrovnÄ› {batch_level}...")
            admin_query = query_builder.build_admin_regions_query(batch_level)
            admin_results = client.execute_query(admin_query)
            admin_regions = admin_results.get('results', {}).get('bindings', [])
            
            if not admin_regions:
                logger.warning("âš ï¸ Nenalezeny Å¾Ã¡dnÃ© administrativnÃ­ celky pro dÃ¡vkovÃ© zpracovÃ¡nÃ­.")
                return 1
            
            logger.info(f"âœ… Nalezeno {len(admin_regions)} administrativnÃ­ch celkÅ¯.")

            # FÃ¡ze 2: Iterace a stahovÃ¡nÃ­ dat pro kaÅ¾dÃ½ celek
            logger.info("FÃ¡ze 2: Stahuji data pro jednotlivÃ© celky...")
            all_bindings = []
            
            progress_bar = tqdm(admin_regions, desc="ZpracovÃ¡vÃ¡m celky", unit="celek")
            for region in progress_bar:
                region_qid = processor.extract_qid(region['region']['value'])
                region_label = region['regionLabel']['value']
                progress_bar.set_description(f"ZpracovÃ¡vÃ¡m: {region_label}")

                # SestavenÃ­ a provedenÃ­ dotazu pro danÃ½ region
                sparql_query = query_builder.build_query(admin_region_qid=region_qid)
                
                # Pro dÃ­lÄÃ­ dotazy nepouÅ¾Ã­vÃ¡me fetch_all_data, ale pÅ™Ã­mo execute_query
                region_data = client.execute_query(sparql_query)
                bindings = region_data.get('results', {}).get('bindings', [])
                
                if bindings:
                    logger.debug(f"  -> Nalezeno {len(bindings)} zÃ¡znamÅ¯ pro {region_label}")
                    all_bindings.extend(bindings)
            
            raw_results = all_bindings

        else: # strategy == 'single_query'
            sparql_query = query_builder.build_query()
            # Pro dry-run se zobrazÃ­ jen hlavnÃ­ dotaz
            if args.dry_run:
                logger.info("\n" + "=" * 70)
                logger.info("SPARQL Dotaz (single_query):")
                logger.info("=" * 70)
                print(sparql_query)
                logger.info("=" * 70)
                return 0
            
            results = client.execute_query(sparql_query)
            raw_results = results.get('results', {}).get('bindings', [])

        # Aplikace --limit aÅ¾ po shromÃ¡Å¾dÄ›nÃ­ vÅ¡ech dat
        if args.limit and len(raw_results) > args.limit:
            logger.info(f"âœ‚ï¸ Omezuji poÄet vÃ½sledkÅ¯ na {args.limit} (z {len(raw_results)})")
            raw_results = raw_results[:args.limit]

        if not raw_results:
            logger.warning("âš ï¸ Å½Ã¡dnÃ¡ data nebyla nalezena")
            return 1
        
        logger.info(f"ğŸ“Š Celkem nalezeno zÃ¡znamÅ¯: {len(raw_results)}")

        # ZpracovÃ¡nÃ­ dat
        processed_data = processor.process_results(raw_results)

        if not processed_data:
            logger.error("âŒ Å½Ã¡dnÃ¡ validnÃ­ data po zpracovÃ¡nÃ­")
            return 1

        # Statistiky zpracovÃ¡nÃ­
        stats = processor.get_processing_stats(processed_data)
        if stats.get('missing_fields'):
            logger.warning("âš ï¸ NÄ›kterÃ© zÃ¡znamy majÃ­ chybÄ›jÃ­cÃ­ hodnoty:")
            for field, count in stats['missing_fields'].items():
                logger.warning(f"  - {field}: {count} zÃ¡znamÅ¯")

        # Export do CSV
        output_path = args.output or config.get('output', 'file_path')
        exported_file = exporter.export(processed_data, output_path)

        # VytvoÅ™enÃ­ reportu
        if args.create_report:
            report = exporter.create_summary_report(processed_data, exported_file)
            print("\n" + report)

        # Statistiky klienta
        client_stats = client.get_statistics()
        logger.info("ğŸ“¡ Statistiky komunikace:")
        logger.info(f"  - Celkem poÅ¾adavkÅ¯: {client_stats['total_requests']}")
        logger.info(f"  - NeÃºspÄ›Å¡nÃ©: {client_stats['failed_requests']}")
        logger.info(f"  - ÃšspÄ›Å¡nost: {client_stats['success_rate']}")

        # CelkovÃ½ Äas
        elapsed_time = time.time() - start_time
        logger.info(f"â±ï¸  CelkovÃ½ Äas: {elapsed_time:.1f}s")

        # FinÃ¡lnÃ­ souhrn
        logger.info("=" * 70)
        logger.info("âœ… Export ÃºspÄ›Å¡nÄ› dokonÄen!")
        logger.info(f"ğŸ“‚ VÃ½stupnÃ­ soubor: {exported_file}")
        logger.info(f"ğŸ“Š ExportovÃ¡no zÃ¡znamÅ¯: {len(processed_data)}")
        logger.info("=" * 70)

        return 0

    except FileNotFoundError as e:
        logger.error(f"âŒ Soubor nenalezen: {e}")
        return 1

    except KeyboardInterrupt:
        logger.warning("\nâš ï¸ PÅ™eruÅ¡eno uÅ¾ivatelem")
        return 1

    except Exception as e:
        logger.error(f"âŒ KritickÃ¡ chyba: {e}", exc_info=True)
        return 1


if __name__ == '__main__':
    sys.exit(main())
